# AI Social Support Application ‚Äî Monorepo

This repository contains a **full, locally-hosted, multimodal AI workflow** that ingests applicant data & attachments, validates facts, scores eligibility, and produces a decision and enablement recommendations ‚Äî all orchestrated via agents and surfaced through a Streamlit UI.

> **Goal:** Automate up to ~99% of eligibility decisions within minutes using local LLMs and a transparent, auditable pipeline.

---

## üß© Architecture Overview

**Core services (microservices):**

- **documents** ‚Äì Ingestion to MinIO + mock OCR/parsers, typed extractors  
  _FastAPI @ `:8001`_
- **extract_validate** ‚Äì Batch extraction (schema-first) + rule-based validation & cross-doc checks  
  _FastAPI @ `:8002`_
- **orchestrator** ‚Äì Agentic pipeline (CrewAI/LangGraph style) coordinating extract ‚Üí validate ‚Üí reconcile ‚Üí score ‚Üí decide  
  _FastAPI @ `:8003` (default)_
- **score** ‚Äì sklearn model serving (LogReg/GBM), SHAP local explainability, model training endpoints  
  _FastAPI @ `:8004`_
- **llm_runtime** ‚Äì gRPC LLM gateway (Ollama/OpenAI providers) used by extraction/agents  
  _gRPC @ `:51051`_
- **recommend** ‚Äì Enablement recommendations (job roles, training), rule-first with optional LLM polishing  
  _FastAPI @ `:8006`_
- **ui** ‚Äì Streamlit front-end (wizard + review/chat)  
  _Streamlit @ `:8501`_

**Shared packages:**

- `packages/schemas` ‚Äì Pydantic models & JSON Schemas
- `packages/llm_protos` ‚Äì gRPC stubs for `llm_runtime` (`llmruntime.v1`)

**Data/infra:**

- **MinIO** ‚Äì object storage for uploaded documents (`documents` service)  
- **MongoDB** ‚Äì application & extracts store (orchestrator)  
- **PostgreSQL** ‚Äì system-of-record (optional)  
- **Redis** ‚Äì chat history & clarifications (orchestrator)  
- **Langfuse** ‚Äì agent/LLM observability (optional, can be disabled for first run)

> Ports above are defaults; see each service‚Äôs `.env.example` for overrides.

### High-level flow

```
UI (Streamlit)
   ‚îî‚îÄ Orchestrator API
       ‚îú‚îÄ documents (/ingest -> MinIO)
       ‚îú‚îÄ extract_validate (/extract/batch, /validate)
       ‚îú‚îÄ score (/score, /explain, /train)
       ‚îú‚îÄ recommend (/recommend/*)
       ‚îî‚îÄ llm_runtime (gRPC) ‚Üí Ollama/OpenAI
```

---

## ‚úÖ Prerequisites

- **Docker** & **Docker Compose** (recommended: Docker Desktop or CLI 20.10+)
- Optional for local dev: **Python 3.11+** and `uv`/`pip`
- **Ollama** (if you want to run LLMs locally outside Docker) or set OpenAI credentials

---

## üöÄ Quick Start (One Command)

From the repository root:

```bash
# 1) Copy environment samples (edit later as needed)
cp services/llm_runtime/.env.example services/llm_runtime/.env || true
cp services/documents/.env.example services/documents/.env || true
cp services/extract_validate/.env.example services/extract_validate/.env || true
# (Repeat for any others you plan to customize)

# 2) Start the full stack
docker compose up -d --build

# 3) Open the UI
# Streamlit UI:
# http://localhost:8501    (or 0.0.0.0:8501 in Docker Desktop)
```

If you‚Äôre running on a server, ensure the listed ports are reachable or use a reverse proxy.

---

## üîß Environment Configuration

Below are the **key** variables per service. Each service ships with a `.env.example` you can copy and adjust.

### `services/documents`
- `DOCS_PORT=8001`
- `MINIO_ENDPOINT=localhost:9000`
- `MINIO_ACCESS_KEY=minioadmin`
- `MINIO_SECRET_KEY=minioadmin`
- `MINIO_SECURE=false`
- `MINIO_BUCKET=documents`
- `ALLOWED_ORIGINS=http://localhost:8501`

### `services/extract_validate`
- `PORT=8002` (if exposed via `.env`/compose)
- `MINIO_*` (if loading from MinIO directly)
- `LLM_RUNTIME_ADDR=llm_runtime:51051` (optional, if using LLM for resume parsing)

### `services/score`
- `SCORE_MODEL_DIR=/app/models/eligibility_v1` (folder must contain `metrics.json` + model)
- `SCORE_PORT=8004`

### `services/orchestrator`
- `EV_BASE_URL=http://extract_validate:8002`
- `SCORE_BASE_URL=http://score:8004` (or `http://localhost:8004` for local dev)
- `REDIS_URL=redis://redis:6379/0` (chat history)
- `MONGO_URL=mongodb://mongo:27017/eligibility`

### `services/llm_runtime`
- `LLMR_LISTEN_HOST=0.0.0.0`
- `LLMR_PORT=51051`
- `DEFAULT_PROVIDER=ollama` (or `openai`)
- `DEFAULT_MODEL=ollama:llama3` (example; remove `ollama:` if provider is openai)
- `OLLAMA_ENDPOINT=http://ollama:11434`
- `OPENAI_BASE_URL=https://api.openai.com/v1`
- `OPENAI_API_KEY=sk-...` (only if using OpenAI)

### `services/recommend`
- `RECO_PORT=8006`
- `RECO_TAXONOMY_PATH=/app/data/taxonomy.json`
- `RECO_LLM_RUNTIME_ADDR=llm_runtime:51051`
- `RECO_LLM_MODEL=` (empty disables polish ‚Üí rules-only)

### Optional: Langfuse (Observability)
If you enabled the `langfuse` stack in Docker:
- Ensure `CLICKHOUSE_USER` & `CLICKHOUSE_PASSWORD` are set.
- Access UI: `http://localhost:3030` (defaults vary).

---

## üß™ Health Checks

After `docker compose up`, verify core services:

```bash
curl -s http://localhost:8001/healthz     # documents
curl -s http://localhost:8002/healthz     # extract_validate
curl -s http://localhost:8004/healthz     # score
curl -s http://localhost:8006/healthz     # recommend
# llm_runtime is gRPC; use logs or client probe
```

---

## üñ•Ô∏è Using the UI (Happy Path)

1. **Open Streamlit**: `http://localhost:8501`
2. **Step 1 ‚Äì Application Form**: fill applicant EID, income, employment, household & dependents, then **Create Draft**.
3. **Step 2 ‚Äì Upload Docs**: upload EID, bank statement, assets/liabilities, credit report, resume; click **Upload, extract & attach**.
4. **Review & Chat** (Page 2): choose your application ‚Üí see facts by doc, validation issues, and chat with the assistant.  
   - The chat is grounded on your application facts & extracts.  
   - Clarification questions raised by the Reconciliation Agent appear here and your answers are saved to Redis.

---

## üõ†Ô∏è API Endpoints (Selected)

> Use these from Postman or `curl` if you prefer scripting.

**documents** (`:8001`):
- `POST /ingest` ‚Äì multipart upload (files) ‚Üí MinIO; returns `DocumentRef[]`
- `POST /extract/bank|eid|resume|assets|credit` ‚Äì mock extractors, return typed facts

**extract_validate** (`:8002`):
- `POST /extract/batch` ‚Äì input: `{application_id, applicant_eid, documents, form?}` ‚Üí `ExtractResult[]`
- `POST /validate` ‚Äì input: `{application_id, form, facts_by_doc}` ‚Üí `ValidationReport`

**score** (`:8004`):
- `POST /score` ‚Äì input: `ApplicationRecord` ‚Üí `{probability, decision}`
- `POST /explain` ‚Äì same input ‚Üí top SHAP features
- `POST /train` ‚Äì upload CSV ‚Üí trains & versions model (writes `/app/models/<ver>`, updates in-memory pointer)
- `GET /thresholds` ‚Äì current approve/review thresholds

**recommend** (`:8006`):
- `POST /recommend/cv` ‚Äì job enablement recommendations from resume facts
- `POST /recommend/match` ‚Äì role matching
- `POST /recommend/skills/gap` ‚Äì skill gap analysis

**orchestrator** (`:8003` typical):
- `GET /applications` ‚Äì list
- `POST /applications/draft` ‚Äì create
- `POST /applications/{eid}/attach-extracts` ‚Äì attach results from `extract_validate`
- `GET /applications/{eid}/details` ‚Äì full view (app + extracts + validation + decision traces)
- `POST /chat` ‚Äì app-scoped chat; history saved in Redis

> Exact routes can evolve; inspect `services/*/app/routers/*.py` for the authoritative list.

---

## üì¶ Model Artifacts (Scoring)

The `score` service expects a **model directory** containing:
- `metrics.json` ‚Üí includes `"model_file"` and evaluation metrics (precision/recall/roc_auc + thresholds)
- The serialized model (e.g., `model.pkl` via `joblib`)

### Train your first model

```bash
# Example: train from CSV (columns should match ApplicationRecord fields + 'eligible' label)
curl -F "file=@/path/to/train.csv" -F "version=eligibility_v1" http://localhost:8004/train
# The service writes to /app/models/<version> and switches the active model
```

### Explain a decision

```bash
curl -X POST http://localhost:8004/explain \
  -H "Content-Type: application/json" \
  -d '{
    "eid": "784198765432101",
    "declared_monthly_income": 12000,
    "family_size": 3,
    "employment_status": "employed",
    "avg_monthly_income": 12000,
    "avg_monthly_expenses": 8000,
    "credit_score": 650,
    "total_debt": 10000,
    "asset_value": 180000,
    "liabilities_value": 90000
  }'
```

---

## üßµ Agentic Pipeline & Traces

- **Extraction Agent** ‚Äì calls `/extract/batch` _exactly once_ and returns `ExtractResult[]`
- **Validation Agent (tool)** ‚Äì runs `/validate`, flags issues (e.g., income mismatch, EID expiry)
- **Reconciliation Agent** ‚Äì consolidates conflicts, may **ask user** via Redis-backed chat
- **Decision Agent** ‚Äì calls `/score`, then merges policy rules + validation ‚Üí `APPROVE | REVIEW | SOFT_DECLINE`
- **Chat** ‚Äì `/chat` endpoint renders the agent questions & user answers; history persisted in Redis

For deep debugging, inspect orchestrator logs and (optionally) Langfuse traces if enabled.

---

## üßë‚Äçüíª Local Dev (Run services individually)

Example ‚Äî **score**:

```bash
cd services/score
uv pip install -r requirements.txt  # or: pip install -r requirements.txt
uvicorn app.main:app --reload --port 8004
```

Example ‚Äî **documents**:

```bash
cd services/documents
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8001
```

> Start `llm_runtime` when you need LLM-backed extraction or agent reasoning:
>
> ```bash
> cd services/llm_runtime
> pip install -r requirements.txt
> python -m app.server
> ```

---

## üîç Troubleshooting

- **UI error: `st.session_state.mode cannot be modified...`**  
  Ensure you set `st.session_state["mode"]` **before** creating widgets bound to `mode`.

- **`Invalid format specifier ... for object of type 'str'` in Decision Agent**  
  This happens when the LLM prints the JSON contract inline within quotes.  
  _Fix_: Orchestrator wrappers already parse LLM output leniently; ensure the Decision Agent prompt ends with a **strict JSON schema** and that `ScoreTool` returns JSON (not text commentary).

- **Langfuse ClickHouse migration complains about `CLICKHOUSE_USER`**  
  Provide `CLICKHOUSE_USER` and `CLICKHOUSE_PASSWORD` in the compose env; verify ClickHouse is reachable before booting Langfuse.

- **`llm_runtime` import / gRPC version mismatch**  
  Make sure `packages/llm_protos` is installed for all services and your `grpcio` version matches the generated stubs.

- **MinIO 403 / bucket not found**  
  The `documents` service creates the bucket on startup (`ensure_bucket()`), but credentials/endpoints must be correct and MinIO must be reachable from the container network.

---

## üîê Security & Privacy (Prototype)

- Local-only LLMs via **Ollama** by default; avoid sending PII externally.  
- Secrets in `.env`, never committed.  
- Logs redact PII where feasible; document hashes for auditability (future work).

---

## üó∫Ô∏è Roadmap (Next)

- Add **household graph** in Neo4j for relationship-aware policies
- Expand real parsers (bank/EID/credit) + production OCR
- Add fairness dashboards and drift monitoring
- Harden decision audit trail and digital signatures

---

## üìÑ License & Credits

Prototype for the AI Social Support case study.  
Built with FastAPI, Streamlit, scikit‚Äëlearn, CrewAI/LangGraph concepts, SHAP, MinIO, and Ollama.
